# –§–∞–π–ª: ollama_clients.py
"""
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π Ollama –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
–¢–æ–ª—å–∫–æ —Å qwen3-vl:4b-model.Modelfile
"""

import os
import sys
import subprocess
import json
import time

class OllamaModelCreator:
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ Modelfile"""
    
    def __init__(self, modelfile_path="/bot/models/qwen3-vl:4b-model.Modelfile"):
        self.modelfile_path = modelfile_path
        self.model_name = "qwen3-vl:4b-model"
        
    def check_ollama_installed(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Ollama"""
        try:
            result = subprocess.run(
                ["ollama", "--version"],
                capture_output=True,
                text=True
            )
            return result.returncode == 0
        except FileNotFoundError:
            return False
    
    def install_ollama(self):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama"""
        print("üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é Ollama...")
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
            install_cmd = "curl -fsSL https://ollama.com/install.sh | sh"
            result = subprocess.run(
                install_cmd,
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                print("‚úÖ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    def start_ollama_server(self):
        """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ Ollama"""
        print("üöÄ –ó–∞–ø—É—Å–∫–∞—é Ollama —Å–µ—Ä–≤–µ—Ä...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—É—â–µ–Ω –ª–∏ —É–∂–µ
        try:
            result = subprocess.run(
                ["pgrep", "ollama"],
                capture_output=True
            )
            if result.returncode == 0:
                print("‚úÖ –°–µ—Ä–≤–µ—Ä —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
                return True
        except:
            pass
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–µ
        try:
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            
            # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
            for i in range(10):
                time.sleep(2)
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ API
                    import requests
                    response = requests.get("http://localhost:11434/api/tags", timeout=2)
                    if response.status_code == 200:
                        print("‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω")
                        return True
                except:
                    print(f"  –û–∂–∏–¥–∞–Ω–∏–µ... {i+1}/10")
            
            print("‚ö†Ô∏è  –°–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Ä—É—á–Ω—É—é: ollama serve")
            return False
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
            return False
    
    def check_model_exists(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        try:
            result = subprocess.run(
                ["ollama", "list"],
                capture_output=True,
                text=True
            )
            
            if self.model_name in result.stdout:
                print(f"‚úÖ –ú–æ–¥–µ–ª—å '{self.model_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                return True
            return False
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
    
    def create_model_from_modelfile(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ Modelfile"""
        print(f"üî® –°–æ–∑–¥–∞—é –º–æ–¥–µ–ª—å '{self.model_name}'...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ Modelfile
        if not os.path.exists(self.modelfile_path):
            print(f"‚ùå –§–∞–π–ª {self.modelfile_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            print("–°–æ–∑–¥–∞—é –±–∞–∑–æ–≤—ã–π Modelfile...")
            self._create_basic_modelfile()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
            result = subprocess.run(
                ["ollama", "create", self.model_name, "-f", self.modelfile_path],
                capture_output=True,
                text=True,
                timeout=300  # 5 –º–∏–Ω—É—Ç
            )
            
            if result.returncode == 0:
                print(f"‚úÖ –ú–æ–¥–µ–ª—å '{self.model_name}' —Å–æ–∑–¥–∞–Ω–∞!")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {result.stderr}")
                
                # –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å
                print("üîÑ –ü—Ä–æ–±—É—é —Å–∫–∞—á–∞—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å...")
                return self.download_base_model()
                
        except subprocess.TimeoutExpired:
            print("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    def _create_basic_modelfile(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ Modelfile –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç"""
        basic_content = """FROM qwen2.5:3b

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ö–∞–∫–∞—Ç–æ–Ω–∞
SYSTEM \"\"\"
–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Ö–∞–∫–∞—Ç–æ–Ω–∞.
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–ü–æ–º–æ–≥–∞–π —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏, –∫–æ–º–∞–Ω–¥–∞—Ö –∏ –ø—Ä–æ–µ–∫—Ç–∞—Ö.
\"\"\"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER num_predict 512
"""
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        os.makedirs(os.path.dirname(self.modelfile_path), exist_ok=True)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        with open(self.modelfile_path, "w") as f:
            f.write(basic_content)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π Modelfile: {self.modelfile_path}")
    
    def download_base_model(self):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            print("üì• –°–∫–∞—á–∏–≤–∞—é –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å qwen2.5:3b...")
            result = subprocess.run(
                ["ollama", "pull", "qwen2.5:3b"],
                capture_output=True,
                text=True,
                timeout=600  # 10 –º–∏–Ω—É—Ç
            )
            
            if result.returncode == 0:
                print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    def test_model(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É—é –º–æ–¥–µ–ª—å...")
        
        try:
            result = subprocess.run(
                ["ollama", "run", self.model_name, "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                print("‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç!")
                print(f"\n–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞:\n{result.stdout[:200]}...")
                return True
            else:
                print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞, –Ω–æ –µ—Å—Ç—å –æ—à–∏–±–∫–∞: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return False
    
    def setup_model(self):
        """–ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏"""
        print("="*60)
        print("üöÄ –ù–ê–°–¢–†–û–ô–ö–ê –ú–û–î–ï–õ–ò OLLAMA")
        print("="*60)
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º Ollama
        if not self.check_ollama_installed():
            print("‚ùå Ollama –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            if not self.install_ollama():
                return False
        
        # 2. –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä
        if not self.start_ollama_server():
            print("‚ö†Ô∏è  –ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ä–≤–µ—Ä–æ–º, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
        if self.check_model_exists():
            # –ú–æ–¥–µ–ª—å —É–∂–µ –µ—Å—Ç—å, —Ç–µ—Å—Ç–∏—Ä—É–µ–º
            return self.test_model()
        
        # 4. –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        if not self.create_model_from_modelfile():
            return False
        
        # 5. –¢–µ—Å—Ç–∏—Ä—É–µ–º
        return self.test_model()

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
model_creator = OllamaModelCreator()


# ============================================================================
# –ü–†–û–°–¢–û–ô –ö–õ–ò–ï–ù–¢ –î–õ–Ø –†–ê–ë–û–¢–´ –° –ú–û–î–ï–õ–¨–Æ
# ============================================================================

class SimpleOllamaClient:
    """–ü—Ä–æ—Å—Ç–æ–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–æ–∑–¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
    
    def __init__(self):
        self.model_name = "qwen3-vl:4b-model"
        self.base_url = "http://localhost:11434"
        
    async def ask(self, question: str) -> str:
        """–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ API"""
        try:
            import requests
            
            payload = {
                "model": self.model_name,
                "prompt": question,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 512
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("response", "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞")
            else:
                return f"–û—à–∏–±–∫–∞ API: {response.status_code}"
                
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"
    
    def ask_sync(self, question: str) -> str:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        try:
            import requests
            import json
            
            payload = {
                "model": self.model_name,
                "prompt": question,
                "stream": False
            }
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("response", "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞")
            else:
                return f"–û—à–∏–±–∫–∞: {response.status_code}"
                
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
simple_client = SimpleOllamaClient()


# ============================================================================
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

if __name__ == "__main__":
    """–ó–∞–ø—É—Å–∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏"""
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É
    success = model_creator.setup_model()
    
    if success:
        print("\n" + "="*60)
        print("üéâ –ú–û–î–ï–õ–¨ –ì–û–¢–û–í–ê –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ!")
        print("="*60)
        
        print("\nüí° –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–æ–¥–µ:")
        print("""
from ollama_clients import simple_client

# –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
response = simple_client.ask_sync("–ü—Ä–∏–≤–µ—Ç! –ß—Ç–æ —Ç–∞–∫–æ–µ —Ö–∞–∫–∞—Ç–æ–Ω?")
print(response)

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ async)
import asyncio
response = asyncio.run(simple_client.ask("–ö–∞–∫ –ø—Ä–æ–π—Ç–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é?"))
print(response)
        """)
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å
        print("\nüß™ –¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å:")
        response = simple_client.ask_sync("–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ –≤ –¥–≤—É—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö.")
        print(f"ü§ñ {response}")
        
    else:
        print("\n" + "="*60)
        print("‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –ù–ê–°–¢–†–û–ò–¢–¨ –ú–û–î–ï–õ–¨")
        print("="*60)
        print("\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é:")
        print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama: curl -fsSL https://ollama.com/install.sh | sh")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä: ollama serve")
        print("3. –°–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å: ollama create qwen3-vl:4b-model -f /models/qwen3-vl:4b-model.Modelfile")
        print("4. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ: ollama run qwen3-vl:4b-model '–ü—Ä–∏–≤–µ—Ç!'")