# –§–∞–π–ª: ollama_client.py
import os
import sys
import subprocess
import time
import ollama
import json

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤ Codespace –∏–ª–∏ GitHub Actions
IS_CODESPACE = os.getenv("CODESPACE_NAME") is not None
IS_GITHUB_ACTIONS = os.getenv("GITHUB_ACTIONS") is not None

class OllamaClient:
    def __init__(self, host="localhost", port=11434, auto_setup=True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            host: –•–æ—Å—Ç Ollama —Å–µ—Ä–≤–µ—Ä–∞
            port: –ü–æ—Ä—Ç Ollama —Å–µ—Ä–≤–µ—Ä–∞
            auto_setup: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å Ollama –≤ Codespace
        """
        self.base_url = f"http://{host}:{port}"
        self.host = host
        self.port = port
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ Codespace –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if auto_setup and (IS_CODESPACE or IS_GITHUB_ACTIONS):
            self._setup_environment()
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∫–ª–∏–µ–Ω—Ç—É
        self.client = self._create_client()
    
    def _setup_environment(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ Codespace/GitHub Actions"""
        print("‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ä–µ–¥–∞ Codespace/GitHub Actions")
        print("   –ü—Ä–æ–≤–µ—Ä—è—é –Ω–∞–ª–∏—á–∏–µ Ollama...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ Ollama
            result = subprocess.run(["which", "ollama"], 
                                  capture_output=True, text=True)
            
            if result.returncode != 0:
                print("üîÑ Ollama –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é...")
                self._install_ollama()
            else:
                print(f"‚úÖ Ollama –Ω–∞–π–¥–µ–Ω: {result.stdout.strip()}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ —Å–µ—Ä–≤–µ—Ä
            if not self._is_ollama_running():
                print("üîÑ –ó–∞–ø—É—Å–∫–∞—é Ollama —Å–µ—Ä–≤–µ—Ä...")
                self._start_ollama_server()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")
            print("   –ü—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ Ollama...")
    
    def _install_ollama(self):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama"""
        try:
            print("–°–∫–∞—á–∏–≤–∞—é —É—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç...")
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
            install_script = """
            curl -fsSL https://ollama.com/install.sh | sh
            """
            
            result = subprocess.run(
                install_script,
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                print("‚úÖ Ollama —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ PATH –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                path_cmd = """
                if [[ ":$PATH:" != *":/usr/local/bin:"* ]]; then
                    echo 'export PATH="$PATH:/usr/local/bin"' >> ~/.bashrc
                    source ~/.bashrc
                fi
                """
                subprocess.run(path_cmd, shell=True, shell=True)
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏: {result.stderr}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ: {e}")
    
    def _is_ollama_running(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –∑–∞–ø—É—â–µ–Ω –ª–∏ Ollama —Å–µ—Ä–≤–µ—Ä"""
        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API
            import requests
            response = requests.get(f"http://{self.host}:{self.port}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
    
    def _start_ollama_server(self):
        """–ó–∞–ø—É—Å–∫ Ollama —Å–µ—Ä–≤–µ—Ä–∞ –≤ —Ñ–æ–Ω–µ"""
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–µ
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            
            # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
            print("‚è≥ –ñ–¥—É –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
            for i in range(10):  # 10 –ø–æ–ø—ã—Ç–æ–∫ –ø–æ 2 —Å–µ–∫—É–Ω–¥—ã = 20 —Å–µ–∫—É–Ω–¥
                time.sleep(2)
                if self._is_ollama_running():
                    print("‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω")
                    return True
                print(f"  –ü–æ–ø—ã—Ç–∫–∞ {i+1}/10...")
            
            print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä. –í–æ–∑–º–æ–∂–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫.")
            print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Ä—É—á–Ω—É—é: ollama serve")
            return False
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")
            return False
    
    def _create_client(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
            if not self._is_ollama_running():
                print("‚ö†Ô∏è  Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –°–æ–∑–¥–∞—é –∑–∞–≥–ª—É—à–∫—É...")
                return MockClient()
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
            return ollama.Client(host=f"{self.host}:{self.port}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞: {e}")
            print("   –ò—Å–ø–æ–ª—å–∑—É—é –∑–∞–≥–ª—É—à–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
            return MockClient()
    
    def list_models(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏"""
        try:
            return self.client.list()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            return {"models": []}
    
    def generate_response(self, model_name, prompt, system_prompt=None, **options):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"""
        try:
            response = self.client.generate(
                model=model_name,
                prompt=prompt,
                system=system_prompt,
                options={
                    'temperature': options.get('temperature', 0.7),
                    'num_predict': options.get('max_tokens', 512),
                    'top_p': options.get('top_p', 0.9),
                    'top_k': options.get('top_k', 40)
                }
            )
            return response['response']
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return self._get_fallback_response(prompt)
    
    def chat_completion(self, model_name, messages, **options):
        """–ß–∞—Ç-–∫–æ–º–ø–ª–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∏—Å—Ç–æ—Ä–∏–µ–π"""
        try:
            response = self.client.chat(
                model=model_name,
                messages=messages,
                options={
                    'temperature': options.get('temperature', 0.7),
                    'num_predict': options.get('max_tokens', 512)
                }
            )
            return response['message']['content']
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á–∞—Ç–∞: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
    
    def stream_response(self, model_name, prompt, callback):
        """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞"""
        try:
            stream = self.client.generate(
                model=model_name,
                prompt=prompt,
                stream=True
            )
            
            full_response = ""
            for chunk in stream:
                if 'response' in chunk:
                    token = chunk['response']
                    full_response += token
                    callback(token)  # –ö–æ–ª–±–µ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
            
            return full_response
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}")
            fallback = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å—Ç—Ä–∏–º–∏–Ω–≥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
            callback(fallback)
            return fallback
    
    def _get_fallback_response(self, prompt):
        """–ó–∞–ø–∞—Å–Ω–æ–π –æ—Ç–≤–µ—Ç –µ—Å–ª–∏ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        prompt_lower = prompt.lower()
        
        if any(word in prompt_lower for word in ["–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "hello", "hi"]):
            return "üëã –ü—Ä–∏–≤–µ—Ç! –Ø AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. Ollama –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ —è –º–æ–≥—É –ø–æ–º–æ—á—å —Å –æ–±—â–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏."
        elif "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ" in prompt_lower:
            return "üìÖ –û–±—ã—á–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Ö–∞–∫–∞—Ç–æ–Ω–∞:\n‚Ä¢ 10:00 - –°—Ç–∞—Ä—Ç\n‚Ä¢ 13:00 - –û–±–µ–¥\n‚Ä¢ 18:00 - –î–µ–º–æ –ø—Ä–æ–µ–∫—Ç–æ–≤"
        elif "–∫–æ–º–∞–Ω–¥–∞" in prompt_lower:
            return "üë• –ò—â–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –Ω–∞ —Å—Ç–µ–Ω–¥–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∏–ª–∏ –≤ –æ–±—â–µ–º —á–∞—Ç–µ!"
        elif "–ø–æ–º–æ—â—å" in prompt_lower:
            return "üÜò –Ø –º–æ–≥—É –ø–æ–º–æ—á—å —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏, –∫–æ–º–∞–Ω–¥–∞—Ö –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏. –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã!"
        else:
            return "ü§ñ –ò–∑–≤–∏–Ω–∏—Ç–µ, AI-—Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–∞–º."


class MockClient:
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ Ollama –∫–æ–≥–¥–∞ –æ–Ω –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω"""
    
    def list(self):
        return {"models": [
            {"name": "test-model", "modified_at": "2024-01-01T00:00:00Z"}
        ]}
    
    def generate(self, model=None, prompt=None, system=None, options=None, **kwargs):
        return {"response": "–≠—Ç–æ mock-–æ—Ç–≤–µ—Ç. Ollama –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω."}
    
    def chat(self, model=None, messages=None, options=None, **kwargs):
        return {"message": {"content": "–≠—Ç–æ mock-—á–∞—Ç –æ—Ç–≤–µ—Ç. Ollama –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω."}}


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
def setup_default_model(model_name="qwen2.5:3b"):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
    print(f"üîÑ –ù–∞—Å—Ç—Ä–∞–∏–≤–∞—é –º–æ–¥–µ–ª—å {model_name}...")
    
    client = OllamaClient()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    models = client.list_models().get('models', [])
    available_models = [m['name'] for m in models]
    
    if model_name in available_models:
        print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É–∂–µ –¥–æ—Å—Ç—É–ø–Ω–∞")
        return True
    
    # –ï—Å–ª–∏ –≤ Codespace, –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å
    if IS_CODESPACE:
        try:
            print(f"üì• –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å {model_name}...")
            subprocess.run(["ollama", "pull", model_name], 
                         capture_output=True, text=True, timeout=300)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —Å–∫–∞—á–∞–Ω–∞")
            return True
        except Exception as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å: {e}")
    
    return False


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Ollama –∫–ª–∏–µ–Ω—Ç–∞...")
    print(f"–°—Ä–µ–¥–∞: {'Codespace' if IS_CODESPACE else 'GitHub Actions' if IS_GITHUB_ACTIONS else '–õ–æ–∫–∞–ª—å–Ω–∞—è'}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
    client = OllamaClient(auto_setup=True)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏
    print("\nüîç –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏...")
    models = client.list_models()
    
    if models.get('models'):
        print("‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
        for model in models['models']:
            print(f"  - {model['name']}")
    else:
        print("‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    print("\nüß™ –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞...")
    
    # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –∑–∞–≥–ª—É—à–∫—É
    test_model = "qwen2.5:3b" if "qwen2.5:3b" in [m['name'] for m in models.get('models', [])] else "test-model"
    
    response = client.generate_response(
        model_name=test_model,
        prompt="–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç —Ö–∞–∫–∞—Ç–æ–Ω?",
        temperature=0.7,
        max_tokens=100
    )
    
    print("ü§ñ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
    print(response)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    print("\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    setup_default_model()
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")